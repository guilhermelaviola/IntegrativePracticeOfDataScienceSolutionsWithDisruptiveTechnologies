{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTs7nSUO+UwsFIovcCEI+V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/IntegrativePracticeOfDataScienceSolutionsWithDisruptiveTechnologies/blob/main/Class08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd3pNcbHMDU4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to Computer Vision with Python**\n",
        "Computer vision, an essential area of artificial intelligence, allows computers to analyze images and videos similarly to humans. Key applications include facial recognition and medical diagnosis, with OpenCV serving as a crucial open-source library for functions like edge detection, object recognition, and motion tracking. Motion detection is utilized in security and autonomous vehicles, while object tracking monitors items over time. Additionally, sentiment analysis improves human-computer interaction by assessing emotions through facial features. Optical Character Recognition (OCR) facilitates text digitization, benefiting historical preservation and aiding the visually impaired. Tools like Teachable Machine allow users to build machine learning models without advanced programming skills. Overall, computer vision is transforming various sectors, driving advancements in health, security, and automation."
      ],
      "metadata": {
        "id": "JLJw4Ve-MIFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF4nyFP_MqeC",
        "outputId": "388f06aa-ebd8-4a51-e367-4bb8c2fa9842"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the necessary libraries and resources:\n",
        "import cv2"
      ],
      "metadata": {
        "id": "4D8rg4hdNJ5f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading a video:\n",
        "video = cv2.VideoCapture('live-to-tell.mp4')\n",
        "\n",
        "if not video.isOpened():\n",
        "  print('Error opening the video!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "nEaHzIBeNQH1",
        "outputId": "ed9777c0-0bc9-4854-8755-99c052c93648"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cv2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3241179633.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading a video:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvideo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'live-to-tell.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the background subtractor techique to identify moving objects:\n",
        "subtractor = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "while True:\n",
        "  ret, frame = video.read()\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "mask = subtractor.apply(frame)\n",
        "\n",
        "cv2.imshow('Mask', mask)\n",
        "\n",
        "if cv2.waitKey(30) & 0xFF == 27:\n",
        "  break\n",
        "\n",
        "video.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "nqzQz8J5ONh7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using tracking algorithms like MeanShift or CAMShift to follow a player or the ball throughout the video:\n",
        "tracker = cv2.TrackerCSRT_create()\n",
        "\n",
        "ret, frame = video.read()\n",
        "bbox = cv2.selectROI(frame, False)\n",
        "tracker.init(frame, bbox)"
      ],
      "metadata": {
        "id": "_JCPb3_4Ohk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oaeBY10jOvj9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}